{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c03805a5",
      "metadata": {
        "id": "c03805a5"
      },
      "outputs": [],
      "source": [
        "#!pip install placekey\n",
        "from placekey.api import PlacekeyAPI\n",
        "from ast import literal_eval\n",
        "import snowflake.connector\n",
        "from snowflake.connector import cursor\n",
        "import usaddress\n",
        "import re\n",
        "import pandas as pd\n",
        "from helper_functions import *\n",
        "import config_final"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b05704da",
      "metadata": {
        "id": "b05704da"
      },
      "outputs": [],
      "source": [
        "ctx = snowflake.connector.connect(\n",
        "    user=config_final.user,\n",
        "    password=config_final.password,\n",
        "    account=config_final.account\n",
        ")\n",
        "cursor = ctx.cursor()\n",
        "\n",
        "sql_MLS = \"\"\" \"\"\"\n",
        "df_MLS = pd.read_sql(sql_MLS, con=ctx)\n",
        "sql_DATATREE = \"\"\" \"\"\"\n",
        "df_DATATREE = pd.read_sql(sql_DATATREE, con=ctx)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1dbb5c49",
      "metadata": {
        "id": "1dbb5c49"
      },
      "source": [
        "## completely match "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "37449f94",
      "metadata": {
        "id": "37449f94",
        "outputId": "fb6aa843-0c90-4458-f37c-cb7ba317472a"
      },
      "outputs": [],
      "source": [
        "# Drop NaN\n",
        "df_MLS.dropna(subset=['MLS_ADDRESS'], inplace=True)\n",
        "df_DATATREE.dropna(subset=['DATATREE_ADDRESS'], inplace=True)\n",
        "# Merge the data\n",
        "df_merge_node1 = pd.merge(df_DATATREE,df_MLS, how = 'left', right_on = ['MLS_ADDRESS', 'POSTALCODE'], \n",
        "                          left_on = ['DATATREE_ADDRESS', 'SITUSZIP5'])\n",
        "# Compute ratio\n",
        "first_node_match = len(df_merge_node1[df_merge_node1['MLS_ADDRESS'].notnull()]['MLS_ADDRESS'].unique())\n",
        "base = len(df_DATATREE['DATATREE_ADDRESS'].unique())\n",
        "first_node_match_ratio = first_node_match/base\n",
        "print(first_node_match_ratio)\n",
        "\n",
        "MLS_matched_address = []\n",
        "DATATREE_matched_address = []\n",
        "\n",
        "first_node_match_list = list(df_merge_node1[df_merge_node1['MLS_ADDRESS'].notnull()]['MLS_ADDRESS'].unique())\n",
        "MLS_matched_address.extend(first_node_match_list)\n",
        "DATATREE_matched_address.extend(first_node_match_list)\n",
        "print(len(MLS_matched_address))\n",
        "print(len(DATATREE_matched_address))\n",
        "df_first_node = df_merge_node1[df_merge_node1['DATATREE_ADDRESS'].isin(DATATREE_matched_address)]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ce1b6bc3",
      "metadata": {
        "id": "ce1b6bc3"
      },
      "source": [
        "## transform and convert address "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d996dfa7",
      "metadata": {
        "id": "d996dfa7"
      },
      "outputs": [],
      "source": [
        "df_MLS = clean_special_char(df_MLS,'MLS_ADDRESS')\n",
        "df_DATATREE = clean_special_char(df_DATATREE,'DATATREE_ADDRESS')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7f58fe14",
      "metadata": {
        "id": "7f58fe14"
      },
      "outputs": [],
      "source": [
        "df1_MLS = df_MLS[:15000] # only take a sample with the first 15000 rows\n",
        "df1_MLS['MLS_ADDRESS_Split'] = df1_MLS.apply(lambda df1_MLS : get_splited_addr(df1_MLS,'MLS_ADDRESS'), axis = 1)\n",
        "df1_DATATREE = df_DATATREE[:15000]\n",
        "df1_DATATREE['DATATREE_ADDRESS_Split'] = df1_DATATREE.apply(lambda df1_DATATREE : get_splited_addr(df1_DATATREE,'DATATREE_ADDRESS'), axis = 1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2fe54538",
      "metadata": {
        "id": "2fe54538"
      },
      "outputs": [],
      "source": [
        "# combine with original dataset\n",
        "# DT_ADDRESS_final.SITUSUNITTYPE.unique()\n",
        "# DT_ADDRESS_final.SITUSSTREET.unique()\n",
        "\n",
        "MLS_ADDRESS_final = get_comb_addr(df1_MLS,'MLS_ADDRESS_Split')\n",
        "DT_ADDRESS_final = get_comb_addr(df1_DATATREE,'DATATREE_ADDRESS_Split')\n",
        "\n",
        "# convert address format (direction, abbreviation)\n",
        "MLS_ADDRESS_final,DT_ADDRESS_final=get_str_replace(MLS_ADDRESS_final,DT_ADDRESS_final)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e45fc61f",
      "metadata": {
        "id": "e45fc61f"
      },
      "outputs": [],
      "source": [
        "# pick some test dataset\n",
        "# DT_ADDRESS_final[(DT_ADDRESS_final['SITUSUNITTYPE']=='unit')&(DT_ADDRESS_final['SITUSSTREET']=='tatum')]\n",
        "test1 = DT_ADDRESS_final[(DT_ADDRESS_final['SITUSUNITTYPE']=='unit')&(DT_ADDRESS_final['SITUSSTREET']=='van buren')]\n",
        "test1 = test1.drop_duplicates(subset='DATATREE_ADDRESS')\n",
        "\n",
        "test2 = DT_ADDRESS_final[(DT_ADDRESS_final['SITUSUNITTYPE']=='apt')&(DT_ADDRESS_final['SITUSSTREET']=='monroe')]\n",
        "test2 = test2.drop_duplicates(subset='DATATREE_ADDRESS')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cac2ca13",
      "metadata": {
        "id": "cac2ca13",
        "outputId": "988dc413-c31f-402a-add2-fac68ebdea2f"
      },
      "outputs": [],
      "source": [
        "test1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9faa6739",
      "metadata": {
        "id": "9faa6739"
      },
      "outputs": [],
      "source": [
        "# test2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ea900840",
      "metadata": {
        "id": "ea900840"
      },
      "outputs": [],
      "source": [
        "test3 = DT_ADDRESS_final[(DT_ADDRESS_final['SITUSUNITTYPE']=='#')&(DT_ADDRESS_final['SITUSSTREET']=='grandview')]\n",
        "# test3\n",
        "# DT_ADDRESS_final[(DT_ADDRESS_final['SITUSUNITTYPE']=='#')].head(70)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "68a0a157",
      "metadata": {
        "id": "68a0a157"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "f7d35121",
      "metadata": {
        "id": "f7d35121"
      },
      "source": [
        "## try with placekey.io "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "54bf7af5",
      "metadata": {
        "id": "54bf7af5"
      },
      "outputs": [],
      "source": [
        "from placekey.api import PlacekeyAPI\n",
        "placekey_api_key = \"n1w1KOroOdSz3BVMMlg8IM4PuflcVP4V\" # fill this in with your personal API key (do not share publicly)\n",
        "pk_api = PlacekeyAPI(placekey_api_key)\n",
        "column_map = {\"DATATREE_ADDRESS\" : \"street_address\", \"SITUSZIP5\": \"postal_code\"}\n",
        "place_keys = (\"city\",\"iso_country_code\",\"postal_code\",\"street_address\",\"query_id\",\"region\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cb57efaa",
      "metadata": {
        "id": "cb57efaa"
      },
      "source": [
        "## DEAL WITH ASSESSOR TABLE"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cc555724",
      "metadata": {
        "id": "cc555724"
      },
      "source": [
        "### Question1: Does the unit signal matter?\n",
        "#### Note1: we want to have certain unit signal before the unit number \n",
        "reasons:\n",
        "1. to get rid of having the same key with different unit numbers\n",
        "2. make sure the key is correct - we don't want to lose original information!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4eef672c",
      "metadata": {
        "id": "4eef672c",
        "outputId": "23f05cc7-a385-4007-e57a-8967ba8352f6"
      },
      "outputs": [],
      "source": [
        "# without unit signal\n",
        "stad_df = get_standard_df(test3,column_map,\"US\", \"phoenix\", \"AZ\")\n",
        "df_placekey = get_placekey_df(pk_api,stad_df,place_keys)\n",
        "pd.concat([df_placekey,test3.reset_index()],axis=1)\n",
        "\n",
        "# notice: query_id #4,5,6 have the same placekey in spite of different unit numbers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0924ec50",
      "metadata": {
        "id": "0924ec50",
        "outputId": "63f05afb-100b-4f3c-96fb-80b989fd6fa9"
      },
      "outputs": [],
      "source": [
        "test3['ColumnA'] = test3[test3.columns[1:8]].apply(\n",
        "    lambda x: ' '.join(x.dropna().astype(str)),\n",
        "    axis=1\n",
        ")\n",
        "column_map = {\"ColumnA\" : \"street_address\", \"SITUSZIP5\": \"postal_code\"}\n",
        "place_keys = (\"city\",\"iso_country_code\",\"postal_code\",\"street_address\",\"query_id\",\"region\")\n",
        "\n",
        "stad_df = get_standard_df(test3,column_map,\"US\", \"phoenix\", \"AZ\")\n",
        "df_placekey = get_placekey_df(pk_api,stad_df,place_keys)\n",
        "pd.concat([df_placekey,test3.reset_index()],axis=1).to_csv('expe.csv')\n",
        "# this time they work fine, but a new issue is generated --> the \"where\" part in #1,#2 changed! "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "17251616",
      "metadata": {
        "id": "17251616",
        "outputId": "c2e1bbf4-4e39-4f90-8075-9a58eff7742c"
      },
      "outputs": [],
      "source": [
        "# another example with unit signal\n",
        "# example with \"monroe\"\n",
        "column_map = {\"DATATREE_ADDRESS\" : \"street_address\", \"SITUSZIP5\": \"postal_code\"}\n",
        "place_keys = (\"city\",\"iso_country_code\",\"postal_code\",\"street_address\",\"query_id\",\"region\")\n",
        "\n",
        "stad_df = get_standard_df(test2,column_map,\"US\", \"phoenix\", \"AZ\")\n",
        "df_placekey = get_placekey_df(pk_api,stad_df,place_keys)\n",
        "pd.concat([df_placekey,test2.reset_index()],axis=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8f360755",
      "metadata": {
        "id": "8f360755"
      },
      "source": [
        "#### conclusioin: \n",
        "1. for Assessor table having detailed address info, we use original address (or the new combined column we generated by ourselves) to match, bc the splited info without \"#\" is not accurate\n",
        "2. api requires an occuring unit signal before unit number "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "248365a9",
      "metadata": {
        "id": "248365a9"
      },
      "source": [
        "### Question2: What's the tolerance for matching accuracy? -- in terms of the \"where\" part\n",
        "#### Note2: we need to figure out what's wrong with the different \"where\" parts given the same addresses with the only difference in their unit info\n",
        "#### description of the newly arised issue : \n",
        "1. the \"where\" part in #1,#2 changed! -- see previous output or the following cell\\\n",
        "* notes: \\\n",
        "when the \"where\" parts have 7 shared prefix => the max distance is 1,176m\\\n",
        "when they have 6 shared prefix => maximal distance is 8,227m"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5df8a3db",
      "metadata": {
        "id": "5df8a3db",
        "outputId": "86c7371c-39f9-4e10-9d76-266d3dea1f30"
      },
      "outputs": [],
      "source": [
        "# this cell is the same as the previous one\n",
        "test3['ColumnA'] = test3[test3.columns[1:8]].apply(\n",
        "    lambda x: ' '.join(x.dropna().astype(str)),\n",
        "    axis=1\n",
        ")\n",
        "# column_map = {\"DATATREE_ADDRESS\" : \"street_address\", \"SITUSZIP5\": \"postal_code\"} # \"what\" fails, \"where\" works\n",
        "column_map = {\"ColumnA\" : \"street_address\", \"SITUSZIP5\": \"postal_code\"} # \"what\" works, \"where\" fails\n",
        "place_keys = (\"city\",\"iso_country_code\",\"postal_code\",\"street_address\",\"query_id\",\"region\")\n",
        "\n",
        "stad_df = get_standard_df(test3,column_map,\"US\", \"phoenix\", \"AZ\")\n",
        "df_placekey = get_placekey_df(pk_api,stad_df,place_keys)\n",
        "pd.concat([df_placekey,test3.reset_index()],axis=1)\n",
        "# .to_csv('az.csv')\n",
        "# this time they work fine, but a new issue is generated --> the \"where\" part in #1,#2 changed! \n",
        "# but this is not always the case -> for index #2,3,4, the placekey works!\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2443d2c7",
      "metadata": {
        "id": "2443d2c7",
        "outputId": "b841ddeb-0601-47d2-f307-f12710e59bd8"
      },
      "outputs": [],
      "source": [
        "# another example with unit signal & the new issued mentioned above\n",
        "# example with \"van buren\"\n",
        "column_map = {\"DATATREE_ADDRESS\" : \"street_address\", \"SITUSZIP5\": \"postal_code\"} # don't need the combined column bc the original address has a unit signal\n",
        "place_keys = (\"city\",\"iso_country_code\",\"postal_code\",\"street_address\",\"query_id\",\"region\")\n",
        "\n",
        "stad_df = get_standard_df(test1,column_map,\"US\", \"phoenix\", \"AZ\")\n",
        "df_placekey = get_placekey_df(pk_api,stad_df,place_keys)\n",
        "pd.concat([df_placekey,test1.reset_index()],axis=1).head(8)\n",
        "\n",
        "# new issue: for index #1,#2,#5, the \"where\" part also changes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e0e02dee",
      "metadata": {
        "id": "e0e02dee",
        "outputId": "7264d7b2-d50c-40b1-89d6-e3fe6254e282"
      },
      "outputs": [],
      "source": [
        "# check original data\n",
        "df_DATATREE[(df_DATATREE['SITUSSTREET']=='van buren')&(df_DATATREE['SITUSDIRECTIONLEFT']=='e')].head(6)\n",
        "# ['DATATREE_ADDRESS'].str.contains('5401 e van buren')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0cc5250a",
      "metadata": {
        "id": "0cc5250a"
      },
      "source": [
        "### Question 3: Wanna change the parameters? "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "51c4acdf",
      "metadata": {
        "id": "51c4acdf"
      },
      "outputs": [],
      "source": [
        "def get_placekey_df(pk_api,stad_df, place_keys:tuple):\n",
        "    # stad_df is the df containing standatdized api fields\n",
        "    import json\n",
        "    # convert query_id to str\n",
        "    stad_df = stad_df.astype({\"query_id\": str})\n",
        "    \n",
        "    # dump df to json-format with selected key-value pairs (only keep values in specified place_keys)\n",
        "    data_jsoned = json.loads(stad_df.to_json(orient=\"records\"))\n",
        "    dict_filter = lambda x, y: dict([ (i,x[i]) for i in x if i in set(y) ])\n",
        "    result_dict=[dict_filter(i, place_keys) for i in data_jsoned]\n",
        "    \n",
        "    #request placekey api\n",
        "    responses = pk_api.lookup_placekeys(result_dict, \n",
        "                                        verbose=True,\n",
        "                                        strict_address_match=False,\n",
        "                                        strict_name_match=False)\n",
        "    df_placekeys = pd.read_json(json.dumps(responses), dtype={'query_id':str}) \n",
        "    # TODO: need to handle missing / errors\n",
        "\n",
        "    return df_placekeys"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c9f4323f",
      "metadata": {
        "id": "c9f4323f"
      },
      "source": [
        "1. strict_address_match: \\\n",
        "If set to true, a Placekey is only returned if all fields identify the place as being at the exact address specified. If set to false, the Placekey returned may ignore unit/apartment/floor information => If strict_address_match is **false**, then address matches are fuzzy across **street_address, city, state, and postal_code**. If strict_address_match is **true**, then we **reject all matches that do not exactly match the input address fields**.\n",
        "\n",
        "2. strict_name_match: (doesn't matter?)\\\n",
        "If set to true, a Placekey is only returned if all fields identify the POI as having the exact name specified => If strict_name_match is false, all location_name matches **after Step 1 are fuzzy**. If strict_name_match is true, all location_name matches are exact case-insensitive.\n",
        "\n",
        "for more info: https://docs.placekey.io/#350ed3a9-68db-4c47-9e20-19b430cb9ef1"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "be2a1d4c",
      "metadata": {
        "id": "be2a1d4c"
      },
      "source": [
        "more info about their matching steps:\n",
        "\n",
        "#### *Matching Behaviour*\n",
        "Our matching algorithm tries a few different queries, sequentially, and returns the best match of the first query to return with high enough score to feel assured it's a true match. Here are the queries it does, in order:\n",
        "\n",
        "1. If the address you've sent in is valid, then we search for a POI at that address placekey with a name that exactly case-insensitively matches the location_name you've sent in.\n",
        "2. If this does not match (or if the address you sent in wasn't valid) but you've sent in a **latitude and longitude** with your query, then we search for that location_name and a fuzzy street address within 1km of your coordinates.\n",
        "3. If this still does not match but you've sent in a postal code, then we search specifically for a POI in that **postal code** and look for a location_name match and a fuzzy street address match\n",
        "4. If none of the above match and you have sent in a city and a region, then we require a strict match on city/region, a match on poi name, and a fuzzy match on street address.\n",
        "5. Finally, if none of the above match, we stop searching for POI and perform an address match.\n",
        "\n",
        "#### our interpretations: \n",
        "1) really doesn't matter? cuz in this step, we're looking for the comparision in varying unit number => the lat and long are the same!\\\n",
        "2) we've matched&generated keys based on the same zipcode => no need to worry about it\n",
        "\n",
        "Q: so we only utilize their 1st step?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d9277167",
      "metadata": {
        "id": "d9277167"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "7fd657ed",
      "metadata": {
        "id": "7fd657ed"
      },
      "source": [
        "### Question 4: How to deal with incomplete unit info? - eg. when the unit signal is #, or it's missing\n",
        "\n",
        "#### notes:\n",
        "1. need to consider situations 1) when the address only has a unit signal without associated number, and 2) when there is no unit signal before the unit number \n",
        "2. **follow-up question**: if there is no unit signal, what should be put to signify the existence of unit?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cd2f2583",
      "metadata": {
        "id": "cd2f2583",
        "outputId": "9fc7e5b3-8986-4b1c-c64d-5b5894967016"
      },
      "outputs": [],
      "source": [
        "df_placekey = get_placekey_df(pk_api,stad_df,place_keys)\n",
        "pd.concat([df_placekey,test1.reset_index()],axis=1).head(6)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8a308f52",
      "metadata": {
        "id": "8a308f52"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "stad_df = stad_df.astype({\"query_id\": str})\n",
        "# dump df to json-format with selected key-value pairs (only keep values in specified place_keys)\n",
        "data_jsoned = json.loads(stad_df.to_json(orient=\"records\"))\n",
        "dict_filter = lambda x, y: dict([ (i,x[i]) for i in x if i in set(y) ])\n",
        "result_dict=[dict_filter(i, place_keys) for i in data_jsoned]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "efe6ebdd",
      "metadata": {
        "id": "efe6ebdd",
        "outputId": "2c6ca78d-4478-4132-dc6e-5a5607977ff1"
      },
      "outputs": [],
      "source": [
        "# output with \"SITUSUNITTYPE\" == \"unit\"\n",
        "df_placekey = get_placekey_df(pk_api,stad_df,place_keys)\n",
        "pd.concat([df_placekey,test1.reset_index()],axis=1).head(6)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d6025d0e",
      "metadata": {
        "id": "d6025d0e"
      },
      "outputs": [],
      "source": [
        "# try to change the unit signal of the original data, see what happens\n",
        "new_result_dict=[{'street_address': '5401 e van buren st apt 1084',\n",
        "  'postal_code': '85008',\n",
        "  'query_id': '1',\n",
        "  'iso_country_code': 'US',\n",
        "  'city': 'phoenix',\n",
        "  'region': 'AZ'},\n",
        " {'street_address': '5401 e van buren st ste 3109',\n",
        "  'postal_code': '85008',\n",
        "  'query_id': '2',\n",
        "  'iso_country_code': 'US',\n",
        "  'city': 'phoenix',\n",
        "  'region': 'AZ'},\n",
        " {'street_address': '5401 e van buren st ste 2101',\n",
        "  'postal_code': '85008',\n",
        "  'query_id': '3',\n",
        "  'iso_country_code': 'US',\n",
        "  'city': 'phoenix',\n",
        "  'region': 'AZ'},\n",
        " {'street_address': '5401 e van buren st ste 3042',\n",
        "  'postal_code': '85008',\n",
        "  'query_id': '4',\n",
        "  'iso_country_code': 'US',\n",
        "  'city': 'phoenix',\n",
        "  'region': 'AZ'},\n",
        " {'street_address': '5302 e van buren st ste 1054',\n",
        "  'postal_code': '85008',\n",
        "  'query_id': '5',\n",
        "  'iso_country_code': 'US',\n",
        "  'city': 'phoenix',\n",
        "  'region': 'AZ'},\n",
        " {'street_address': '5345 e van buren st ste 325',\n",
        "  'postal_code': '85008',\n",
        "  'query_id': '6',\n",
        "  'iso_country_code': 'US',\n",
        "  'city': 'phoenix',\n",
        "  'region': 'AZ'},\n",
        " {'street_address': '5401 e van buren st ste 2120',\n",
        "  'postal_code': '85008',\n",
        "  'query_id': '7',\n",
        "  'iso_country_code': 'US',\n",
        "  'city': 'phoenix',\n",
        "  'region': 'AZ'}]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "90f8fef0",
      "metadata": {
        "id": "90f8fef0",
        "outputId": "7dbb6057-f88b-410b-cd8d-3870ebce820a"
      },
      "outputs": [],
      "source": [
        "# output with \"SITUSUNITTYPE\" != \"unit\"\n",
        "responses = pk_api.lookup_placekeys(new_result_dict, \n",
        "                                    verbose=True,\n",
        "                                    strict_address_match=False,\n",
        "                                    strict_name_match=False)\n",
        "df_placekeys = pd.read_json(json.dumps(responses), dtype={'query_id':str})\n",
        "pd.concat([df_placekey,test1.reset_index()],axis=1).head(6)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b264fc0d",
      "metadata": {
        "id": "b264fc0d",
        "outputId": "9c20043e-e4b1-49f8-97a1-c1cafd6a6040"
      },
      "outputs": [],
      "source": [
        "DT_ADDRESS_final.SITUSUNITTYPE.unique()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3eefaac5",
      "metadata": {
        "id": "3eefaac5"
      },
      "source": [
        "#### conlusion:\n",
        "1. when we change unit types, the output placekeys are sill the same => so the varying unit types might not be a big issue (but we need to test with more data for sure!)\n",
        "2. when \"#\" occues, maybe we can substitue it with the unit type occuring in the highest frequency? then we can create a new column with combined address info"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a358c118",
      "metadata": {
        "id": "a358c118"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "Placekey.io-withUnit.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
